{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1. What are the three stages to build the hypotheses or model in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "Following are the three stages to build the hypotheses or model in machine learning:\n",
    "\n",
    "a) Model building - Select the algorithm, Engineer features\n",
    "\n",
    "b) Model testing  - Assess performance, compare alternatives, Score Models \n",
    "\n",
    "c) Applying the model - Apply model to fresh data, Monitor outcomes, Improve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2. What is the standard approach to supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "The standard approach to supervised learning is to split the set of example \n",
    "into the training set and the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3. What is Training set and Test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "Training Set: In Machine Learning, a training set is a dataset used to train a model. \n",
    "In training the model, specific features are picked out from the training set. \n",
    "These features are then incorporated into the model. Thereby, if the training set is \n",
    "labeled correctly, the model should be able to learn something from these features.\n",
    "\n",
    "Test Set: The test set is a dataset used to measure how well the model performs at \n",
    "making predictions on that test set. If the prediction scores for the test set \n",
    "are unreasonable, we’ll have to make some adjustments to our model and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4. What is the general principle of an ensemble method and what is bagging and\n",
    "# boosting in ensemble method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "General principle of ensemble method – \n",
    "\n",
    "Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive model \n",
    "in order to decrease variance (bagging), bias (boosting), or improve predictions (stacking).\n",
    "\n",
    "Bagging – \n",
    "\n",
    "Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability \n",
    "and accuracy of machine learning algorithms used in statistical classification and regression. \n",
    "It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, \n",
    "it can be used with any type of method. Bagging is a special case of the model averaging approach.\n",
    "Bagging uses bootstrap sampling to obtain the data subsets for training the base learners. For aggregating the outputs of base learners, \n",
    "bagging uses voting for classification and averaging for regression.\n",
    "\n",
    "Boosting – \n",
    "\n",
    "Boosting is a machine learning ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, \n",
    "and a family of machine learning algorithms that convert weak learners to strong ones.\n",
    "Boosting refers to a family of algorithms that are able to convert weak learners to strong learners. \n",
    "The main principle of boosting is to fit a sequence of weak learners− models that are only slightly better than \n",
    "random guessing, such as small decision trees− to weighted versions of the data.\n",
    "The predictions are then combined through a weighted majority vote (classification) or a weighted sum (regression) \n",
    "to produce the final prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5. How can you avoid overfitting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "Overfitting can be avoided with help of following methods\n",
    "\n",
    "1. Cross-Validation  - powerful preventative measure against overfitting. Cross-validation allows you to tune hyperparameters with only your original training set. This allows you to keep your test set as a truly unseen dataset for selecting your final model.\n",
    "\n",
    "\n",
    "2. Take more data    - Can help algorithms detect the signal better\n",
    "\n",
    "\n",
    "3. Feature Selection - Some algorithms have built-in feature selection.For those that don’t, you can manually improve their generalizability by removing irrelevant input features.\n",
    "\n",
    "\n",
    "4. Regularization    - Regularization refers to a broad range of techniques for artificially forcing your model to be simpler.The method will depend on the type of learner you’re using.For example, you could prune a decision tree,use dropout on a neural network, or add a penalty parameter to the cost function in regression.Oftentimes, the regularization method is a hyperparameter as well, which means it can be tuned through cross-validation.\n",
    "                \n",
    "                \n",
    "5. Pre-pruning       - To stop the growing Decision tree before it is fully gone.\n",
    "\n",
    "\n",
    "6. Post-pruning      - Allow the Decision tree to grow with no size limit. After tree completion, start pruning the tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
